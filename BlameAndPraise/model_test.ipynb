{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-19T17:55:21.055276Z",
     "start_time": "2025-01-19T17:55:16.743012Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from model_script import perform_preprocessing, read_txt_file, read_sentences, perform_preprocessing_from_dict\n",
    "from Sentiment.sentiment_script import vader_sentiment\n",
    "from NewsSentiment import TargetSentimentClassifier\n",
    "from NewsSentiment.customexceptions import TargetNotFoundException, TooLongTextException\n",
    "import warnings\n",
    "from Sentiment.sentiment_script import vader_sentiment"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T17:56:45.196718Z",
     "start_time": "2025-01-19T17:55:21.060288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "directory_Ania = \"../BRAT_Data/Ukraine_after/Articles_for_Ania\"\n",
    "all_dataframes_Ania, all_sentences_Ania = perform_preprocessing_from_dict(directory_Ania)\n",
    "all_dataframes_Ania"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 470/470 [00:14<00:00, 32.69it/s] \n",
      "0it [00:00, ?it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.70batch/s]\u001B[A\n",
      "1it [00:00,  1.69it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.88batch/s]\u001B[A\n",
      "2it [00:01,  1.79it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.96batch/s]\u001B[A\n",
      "3it [00:01,  1.86it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.86batch/s]\u001B[A\n",
      "4it [00:02,  1.85it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.77batch/s]\u001B[A\n",
      "5it [00:02,  1.82it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.77batch/s]\u001B[A\n",
      "6it [00:03,  1.79it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.89batch/s]\u001B[A\n",
      "7it [00:03,  1.82it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.62batch/s]\u001B[A\n",
      "8it [00:04,  1.75it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.64batch/s]\u001B[A\n",
      "9it [00:05,  1.71it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.82batch/s]\u001B[A\n",
      "10it [00:05,  1.74it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.78batch/s]\u001B[A\n",
      "11it [00:06,  1.75it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.86batch/s]\u001B[A\n",
      "12it [00:06,  1.78it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.73batch/s]\u001B[A\n",
      "13it [00:07,  1.76it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.53batch/s]\u001B[A\n",
      "14it [00:07,  1.68it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.77batch/s]\u001B[A\n",
      "15it [00:08,  1.70it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.42batch/s]\u001B[A\n",
      "16it [00:09,  1.61it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.19batch/s]\u001B[A\n",
      "17it [00:10,  1.45it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.78batch/s]\u001B[A\n",
      "18it [00:10,  1.53it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.71batch/s]\u001B[A\n",
      "19it [00:11,  1.58it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.78batch/s]\u001B[A\n",
      "20it [00:11,  1.63it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.70batch/s]\u001B[A\n",
      "21it [00:12,  1.65it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.89batch/s]\u001B[A\n",
      "22it [00:12,  1.71it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.81batch/s]\u001B[A\n",
      "23it [00:13,  1.74it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.33batch/s]\u001B[A\n",
      "24it [00:14,  1.59it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.72batch/s]\u001B[A\n",
      "25it [00:14,  1.62it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.34batch/s]\u001B[A\n",
      "26it [00:15,  1.53it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.34batch/s]\u001B[A\n",
      "27it [00:16,  1.46it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.37batch/s]\u001B[A\n",
      "28it [00:17,  1.43it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.36batch/s]\u001B[A\n",
      "29it [00:17,  1.40it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.35batch/s]\u001B[A\n",
      "30it [00:18,  1.39it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.35batch/s]\u001B[A\n",
      "31it [00:19,  1.37it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.19batch/s]\u001B[A\n",
      "32it [00:20,  1.31it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.07batch/s]\u001B[A\n",
      "33it [00:21,  1.22it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.73batch/s]\u001B[A\n",
      "34it [00:21,  1.34it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.40batch/s]\u001B[A\n",
      "35it [00:22,  1.36it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.41batch/s]\u001B[A\n",
      "36it [00:23,  1.37it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.56batch/s]\u001B[A\n",
      "37it [00:23,  1.42it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.54batch/s]\u001B[A\n",
      "38it [00:24,  1.45it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.72batch/s]\u001B[A\n",
      "39it [00:24,  1.52it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.81batch/s]\u001B[A\n",
      "40it [00:25,  1.59it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.91batch/s]\u001B[A\n",
      "41it [00:26,  1.67it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.41batch/s]\u001B[A\n",
      "42it [00:26,  1.58it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.43batch/s]\u001B[A\n",
      "43it [00:27,  1.53it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.62batch/s]\u001B[A\n",
      "44it [00:28,  1.55it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.57batch/s]\u001B[A\n",
      "45it [00:28,  1.56it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.66batch/s]\u001B[A\n",
      "46it [00:29,  1.58it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.37batch/s]\u001B[A\n",
      "47it [00:30,  1.51it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TooLongTextException: russia - Sentence too long for TSC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.59batch/s]\u001B[A\n",
      "49it [00:30,  1.98it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.17batch/s]\u001B[A\n",
      "50it [00:31,  1.69it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.19batch/s]\u001B[A\n",
      "51it [00:32,  1.52it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.24batch/s]\u001B[A\n",
      "52it [00:33,  1.43it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.28batch/s]\u001B[A\n",
      "53it [00:34,  1.38it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.68batch/s]\u001B[A\n",
      "54it [00:34,  1.45it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.74batch/s]\u001B[A\n",
      "55it [00:35,  1.52it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.80batch/s]\u001B[A\n",
      "56it [00:35,  1.59it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.80batch/s]\u001B[A\n",
      "57it [00:36,  1.65it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.24batch/s]\u001B[A\n",
      "58it [00:37,  1.50it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.21batch/s]\u001B[A\n",
      "59it [00:37,  1.40it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.51batch/s]\u001B[A\n",
      "60it [00:38,  1.43it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.61batch/s]\u001B[A\n",
      "61it [00:39,  1.47it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.85batch/s]\u001B[A\n",
      "62it [00:39,  1.57it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.79batch/s]\u001B[A\n",
      "63it [00:40,  1.62it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.75batch/s]\u001B[A\n",
      "64it [00:40,  1.66it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.74batch/s]\u001B[A\n",
      "65it [00:41,  1.68it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.75batch/s]\u001B[A\n",
      "66it [00:42,  1.69it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.83batch/s]\u001B[A\n",
      "67it [00:42,  1.73it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.45batch/s]\u001B[A\n",
      "68it [00:43,  1.63it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.42batch/s]\u001B[A\n",
      "69it [00:44,  1.56it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.40batch/s]\u001B[A\n",
      "70it [00:44,  1.50it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.46batch/s]\u001B[A\n",
      "71it [00:45,  1.49it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.89batch/s]\u001B[A\n",
      "72it [00:45,  1.59it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.97batch/s]\u001B[A\n",
      "73it [00:46,  1.68it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.51batch/s]\u001B[A\n",
      "74it [00:47,  1.62it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.56batch/s]\u001B[A\n",
      "75it [00:47,  1.60it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.50batch/s]\u001B[A\n",
      "76it [00:48,  1.57it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.36batch/s]\u001B[A\n",
      "77it [00:49,  1.50it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.37batch/s]\u001B[A\n",
      "78it [00:49,  1.45it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.94batch/s]\u001B[A\n",
      "79it [00:50,  1.57it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.88batch/s]\u001B[A\n",
      "80it [00:51,  1.65it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.79batch/s]\u001B[A\n",
      "81it [00:51,  1.69it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.88batch/s]\u001B[A\n",
      "82it [00:52,  1.74it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.68batch/s]\u001B[A\n",
      "83it [00:52,  1.72it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.58batch/s]\u001B[A\n",
      "84it [00:53,  1.67it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.68batch/s]\u001B[A\n",
      "85it [00:53,  1.67it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.54batch/s]\u001B[A\n",
      "86it [00:54,  1.62it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.83batch/s]\u001B[A\n",
      "87it [00:55,  1.68it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.78batch/s]\u001B[A\n",
      "88it [00:55,  1.71it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.81batch/s]\u001B[A\n",
      "89it [00:56,  1.73it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.77batch/s]\u001B[A\n",
      "90it [00:56,  1.74it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.83batch/s]\u001B[A\n",
      "91it [00:57,  1.76it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.82batch/s]\u001B[A\n",
      "92it [00:57,  1.78it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.84batch/s]\u001B[A\n",
      "93it [00:58,  1.79it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.74batch/s]\u001B[A\n",
      "94it [00:59,  1.77it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.72batch/s]\u001B[A\n",
      "95it [00:59,  1.75it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.50batch/s]\u001B[A\n",
      "96it [01:00,  1.67it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.33batch/s]\u001B[A\n",
      "97it [01:01,  1.55it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.72batch/s]\u001B[A\n",
      "98it [01:01,  1.59it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.64batch/s]\u001B[A\n",
      "99it [01:02,  1.60it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.66batch/s]\u001B[A\n",
      "100it [01:02,  1.61it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.91batch/s]\u001B[A\n",
      "101it [01:03,  1.69it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.59batch/s]\u001B[A\n",
      "102it [01:04,  1.66it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.67batch/s]\u001B[A\n",
      "103it [01:04,  1.66it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\n",
      "104it [01:04,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TooLongTextException: china - Sentence too long for TSC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    annotation_category                                         annotation  \\\n",
       "0                 blame  new arms deliveries to Kiev are aimed at \"prol...   \n",
       "1                 blame  has been sending more advanced and heavier wea...   \n",
       "2                 blame  clearly knows that a prolonged conflict betwee...   \n",
       "3                 blame  has put its national interests into considerat...   \n",
       "4                 blame  With self-interests in mind, the US will not s...   \n",
       "..                  ...                                                ...   \n",
       "99                blame  is self-sufficient in energy, it has dragged E...   \n",
       "100              praise  has the advantage of owning a complete global ...   \n",
       "101              praise  will have China's full advantages of technolog...   \n",
       "102              praise  have accelerated the pace of investment and fa...   \n",
       "103              praise                            is an ideal destination   \n",
       "\n",
       "               entity                                           sentence  \\\n",
       "0                  US  Speaking to the Rossiya-1 state television cha...   \n",
       "1                  US  From the beginning, the US has been sending mo...   \n",
       "2                  US  The US clearly knows that a prolonged conflict...   \n",
       "3                  US  The US has put its national interests into con...   \n",
       "4                  US  With self-interests in mind, the US will not s...   \n",
       "..                ...                                                ...   \n",
       "99                 US  \"If the EU wants to import lots of LNG from th...   \n",
       "100             China  \"China has the advantage of owning a complete ...   \n",
       "101           China's  If the top segment of the EU's industry chain ...   \n",
       "102  German companies  If the top segment of the EU's industry chain ...   \n",
       "103             China  Europe is being forced to cut itself off from ...   \n",
       "\n",
       "    entity_atomized sentiment tsc_sentiment  \n",
       "0                US  negative       neutral  \n",
       "1                US  negative       neutral  \n",
       "2                US  positive       neutral  \n",
       "3                US  positive      positive  \n",
       "4                US  negative      positive  \n",
       "..              ...       ...           ...  \n",
       "99               US  negative       neutral  \n",
       "100           China  positive      positive  \n",
       "101           China  positive       neutral  \n",
       "102          German  positive       neutral  \n",
       "103           China  negative          None  \n",
       "\n",
       "[104 rows x 7 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation_category</th>\n",
       "      <th>annotation</th>\n",
       "      <th>entity</th>\n",
       "      <th>sentence</th>\n",
       "      <th>entity_atomized</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tsc_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blame</td>\n",
       "      <td>new arms deliveries to Kiev are aimed at \"prol...</td>\n",
       "      <td>US</td>\n",
       "      <td>Speaking to the Rossiya-1 state television cha...</td>\n",
       "      <td>US</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blame</td>\n",
       "      <td>has been sending more advanced and heavier wea...</td>\n",
       "      <td>US</td>\n",
       "      <td>From the beginning, the US has been sending mo...</td>\n",
       "      <td>US</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blame</td>\n",
       "      <td>clearly knows that a prolonged conflict betwee...</td>\n",
       "      <td>US</td>\n",
       "      <td>The US clearly knows that a prolonged conflict...</td>\n",
       "      <td>US</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blame</td>\n",
       "      <td>has put its national interests into considerat...</td>\n",
       "      <td>US</td>\n",
       "      <td>The US has put its national interests into con...</td>\n",
       "      <td>US</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blame</td>\n",
       "      <td>With self-interests in mind, the US will not s...</td>\n",
       "      <td>US</td>\n",
       "      <td>With self-interests in mind, the US will not s...</td>\n",
       "      <td>US</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>blame</td>\n",
       "      <td>is self-sufficient in energy, it has dragged E...</td>\n",
       "      <td>US</td>\n",
       "      <td>\"If the EU wants to import lots of LNG from th...</td>\n",
       "      <td>US</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>praise</td>\n",
       "      <td>has the advantage of owning a complete global ...</td>\n",
       "      <td>China</td>\n",
       "      <td>\"China has the advantage of owning a complete ...</td>\n",
       "      <td>China</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>praise</td>\n",
       "      <td>will have China's full advantages of technolog...</td>\n",
       "      <td>China's</td>\n",
       "      <td>If the top segment of the EU's industry chain ...</td>\n",
       "      <td>China</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>praise</td>\n",
       "      <td>have accelerated the pace of investment and fa...</td>\n",
       "      <td>German companies</td>\n",
       "      <td>If the top segment of the EU's industry chain ...</td>\n",
       "      <td>German</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>praise</td>\n",
       "      <td>is an ideal destination</td>\n",
       "      <td>China</td>\n",
       "      <td>Europe is being forced to cut itself off from ...</td>\n",
       "      <td>China</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 7 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T18:00:28.799406Z",
     "start_time": "2025-01-19T17:56:45.525250Z"
    }
   },
   "cell_type": "code",
   "source": [
    "directory_Agnieszka = \"../BRAT_Data/Ukraine_after/Articles_for_Agnieszka\"\n",
    "all_dataframes_Agnieszka, all_sentences_Agnieszka = perform_preprocessing_from_dict(directory_Agnieszka)\n",
    "all_dataframes_Agnieszka"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 470/470 [00:19<00:00, 23.62it/s] \n",
      "0it [00:00, ?it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.98batch/s]\u001B[A\n",
      "1it [00:00,  1.97it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.70batch/s]\u001B[A\n",
      "2it [00:01,  1.79it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.80batch/s]\u001B[A\n",
      "3it [00:01,  1.79it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.81batch/s]\u001B[A\n",
      "4it [00:02,  1.79it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.84batch/s]\u001B[A\n",
      "5it [00:02,  1.81it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.55batch/s]\u001B[A\n",
      "6it [00:03,  1.71it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.80batch/s]\u001B[A\n",
      "7it [00:03,  1.73it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.83batch/s]\u001B[A\n",
      "8it [00:04,  1.76it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.87batch/s]\u001B[A\n",
      "9it [00:05,  1.79it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.82batch/s]\u001B[A\n",
      "10it [00:05,  1.79it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.71batch/s]\u001B[A\n",
      "11it [00:06,  1.77it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.72batch/s]\u001B[A\n",
      "12it [00:06,  1.75it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.87batch/s]\u001B[A\n",
      "13it [00:07,  1.78it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.95batch/s]\u001B[A\n",
      "14it [00:07,  1.82it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.57batch/s]\u001B[A\n",
      "15it [00:08,  1.74it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.51batch/s]\u001B[A\n",
      "16it [00:09,  1.66it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.52batch/s]\u001B[A\n",
      "17it [00:09,  1.61it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.99batch/s]\u001B[A\n",
      "18it [00:10,  1.71it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.35batch/s]\u001B[A\n",
      "19it [00:11,  1.58it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.41batch/s]\u001B[A\n",
      "20it [00:11,  1.52it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.63batch/s]\u001B[A\n",
      "21it [00:12,  1.55it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.65batch/s]\u001B[A\n",
      "22it [00:12,  1.58it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.81batch/s]\u001B[A\n",
      "23it [00:13,  1.64it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.54batch/s]\u001B[A\n",
      "24it [00:14,  1.60it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.52batch/s]\u001B[A\n",
      "25it [00:14,  1.57it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.54batch/s]\u001B[A\n",
      "26it [00:15,  1.56it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.59batch/s]\u001B[A\n",
      "27it [00:16,  1.57it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.65batch/s]\u001B[A\n",
      "28it [00:16,  1.59it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.58batch/s]\u001B[A\n",
      "29it [00:17,  1.58it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.78batch/s]\u001B[A\n",
      "30it [00:17,  1.63it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.79batch/s]\u001B[A\n",
      "31it [00:18,  1.67it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.85batch/s]\u001B[A\n",
      "32it [00:19,  1.72it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.76batch/s]\u001B[A\n",
      "33it [00:19,  1.73it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.88batch/s]\u001B[A\n",
      "34it [00:20,  1.77it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.82batch/s]\u001B[A\n",
      "35it [00:20,  1.78it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.80batch/s]\u001B[A\n",
      "36it [00:21,  1.78it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.82batch/s]\u001B[A\n",
      "37it [00:21,  1.79it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.73batch/s]\u001B[A\n",
      "38it [00:22,  1.77it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.25batch/s]\u001B[A\n",
      "39it [00:23,  1.57it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TooLongTextException: russian - Sentence too long for TSC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.29batch/s]\u001B[A\n",
      "41it [00:24,  1.90it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.32batch/s]\u001B[A\n",
      "42it [00:24,  1.71it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.30batch/s]\u001B[A\n",
      "43it [00:25,  1.58it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.62batch/s]\u001B[A\n",
      "44it [00:26,  1.59it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.70batch/s]\u001B[A\n",
      "45it [00:26,  1.61it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.81batch/s]\u001B[A\n",
      "46it [00:27,  1.66it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.92batch/s]\u001B[A\n",
      "47it [00:27,  1.73it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.97batch/s]\u001B[A\n",
      "48it [00:28,  1.79it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.83batch/s]\u001B[A\n",
      "49it [00:28,  1.80it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.81batch/s]\u001B[A\n",
      "50it [00:29,  1.80it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.56batch/s]\u001B[A\n",
      "51it [00:30,  1.72it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:01<00:00,  1.06s/batch]\u001B[A\n",
      "52it [00:31,  1.37it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.30batch/s]\u001B[A\n",
      "53it [00:31,  1.35it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.29batch/s]\u001B[A\n",
      "54it [00:32,  1.33it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.17batch/s]\u001B[A\n",
      "55it [00:33,  1.28it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.40batch/s]\u001B[A\n",
      "56it [00:34,  1.31it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.22batch/s]\u001B[A\n",
      "57it [00:35,  1.28it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.49batch/s]\u001B[A\n",
      "58it [00:35,  1.33it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.46batch/s]\u001B[A\n",
      "59it [00:36,  1.37it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.46batch/s]\u001B[A\n",
      "60it [00:37,  1.39it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.41batch/s]\u001B[A\n",
      "61it [00:37,  1.39it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.55batch/s]\u001B[A\n",
      "62it [00:38,  1.43it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.43batch/s]\u001B[A\n",
      "63it [00:39,  1.43it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.73batch/s]\u001B[A\n",
      "64it [00:39,  1.51it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.38batch/s]\u001B[A\n",
      "65it [00:40,  1.46it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.49batch/s]\u001B[A\n",
      "66it [00:41,  1.47it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.58batch/s]\u001B[A\n",
      "67it [00:41,  1.50it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.55batch/s]\u001B[A\n",
      "68it [00:42,  1.51it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.53batch/s]\u001B[A\n",
      "69it [00:43,  1.52it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.73batch/s]\u001B[A\n",
      "70it [00:43,  1.57it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.70batch/s]\u001B[A\n",
      "71it [00:44,  1.61it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.62batch/s]\u001B[A\n",
      "72it [00:44,  1.60it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.68batch/s]\u001B[A\n",
      "73it [00:45,  1.62it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.76batch/s]\u001B[A\n",
      "74it [00:46,  1.66it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.58batch/s]\u001B[A\n",
      "75it [00:46,  1.63it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.72batch/s]\u001B[A\n",
      "76it [00:47,  1.65it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.76batch/s]\u001B[A\n",
      "77it [00:47,  1.68it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.97batch/s]\u001B[A\n",
      "78it [00:48,  1.76it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  2.01batch/s]\u001B[A\n",
      "79it [00:48,  1.82it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.78batch/s]\u001B[A\n",
      "80it [00:49,  1.80it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.94batch/s]\u001B[A\n",
      "81it [00:50,  1.84it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.89batch/s]\u001B[A\n",
      "82it [00:50,  1.85it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.90batch/s]\u001B[A\n",
      "83it [00:51,  1.86it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.52batch/s]\u001B[A\n",
      "84it [00:51,  1.74it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.37batch/s]\u001B[A\n",
      "85it [00:52,  1.61it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.59batch/s]\u001B[A\n",
      "86it [00:53,  1.60it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.26batch/s]\u001B[A\n",
      "87it [00:53,  1.48it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.14batch/s]\u001B[A\n",
      "88it [00:54,  1.35it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.24batch/s]\u001B[A\n",
      "89it [00:55,  1.32it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.36batch/s]\u001B[A\n",
      "90it [00:56,  1.33it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.22batch/s]\u001B[A\n",
      "91it [00:57,  1.29it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.30batch/s]\u001B[A\n",
      "92it [00:57,  1.29it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.25batch/s]\u001B[A\n",
      "93it [00:58,  1.28it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.34batch/s]\u001B[A\n",
      "94it [00:59,  1.29it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.28batch/s]\u001B[A\n",
      "95it [01:00,  1.29it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.52batch/s]\u001B[A\n",
      "96it [01:00,  1.35it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.61batch/s]\u001B[A\n",
      "97it [01:01,  1.41it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.41batch/s]\u001B[A\n",
      "98it [01:02,  1.41it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.62batch/s]\u001B[A\n",
      "99it [01:02,  1.47it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.62batch/s]\u001B[A\n",
      "100it [01:03,  1.51it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.71batch/s]\u001B[A\n",
      "101it [01:04,  1.56it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.61batch/s]\u001B[A\n",
      "102it [01:04,  1.57it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.34batch/s]\u001B[A\n",
      "103it [01:05,  1.49it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.32batch/s]\u001B[A\n",
      "104it [01:06,  1.43it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.31batch/s]\u001B[A\n",
      "105it [01:07,  1.39it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.32batch/s]\u001B[A\n",
      "106it [01:07,  1.37it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.61batch/s]\u001B[A\n",
      "107it [01:08,  1.43it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.78batch/s]\u001B[A\n",
      "108it [01:08,  1.52it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.76batch/s]\u001B[A\n",
      "109it [01:09,  1.58it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.71batch/s]\u001B[A\n",
      "110it [01:10,  1.62it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.45batch/s]\u001B[A\n",
      "111it [01:10,  1.56it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.52batch/s]\u001B[A\n",
      "112it [01:11,  1.55it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.48batch/s]\u001B[A\n",
      "113it [01:12,  1.52it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.41batch/s]\u001B[A\n",
      "114it [01:12,  1.48it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.41batch/s]\u001B[A\n",
      "115it [01:13,  1.46it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.40batch/s]\u001B[A\n",
      "116it [01:14,  1.44it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.27batch/s]\u001B[A\n",
      "117it [01:15,  1.38it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.03batch/s]\u001B[A\n",
      "118it [01:16,  1.25it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.24batch/s]\u001B[A\n",
      "119it [01:16,  1.25it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.27batch/s]\u001B[A\n",
      "120it [01:17,  1.25it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.67batch/s]\u001B[A\n",
      "121it [01:18,  1.35it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.72batch/s]\u001B[A\n",
      "122it [01:18,  1.44it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.67batch/s]\u001B[A\n",
      "123it [01:19,  1.50it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.69batch/s]\u001B[A\n",
      "124it [01:20,  1.55it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.28batch/s]\u001B[A\n",
      "125it [01:20,  1.45it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.43batch/s]\u001B[A\n",
      "126it [01:21,  1.44it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.50batch/s]\u001B[A\n",
      "127it [01:22,  1.46it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.03batch/s]\u001B[A\n",
      "128it [01:23,  1.29it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.40batch/s]\u001B[A\n",
      "129it [01:23,  1.32it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.43batch/s]\u001B[A\n",
      "130it [01:24,  1.35it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.55batch/s]\u001B[A\n",
      "131it [01:25,  1.40it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.68batch/s]\u001B[A\n",
      "132it [01:25,  1.47it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.74batch/s]\u001B[A\n",
      "133it [01:26,  1.54it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.60batch/s]\u001B[A\n",
      "134it [01:27,  1.56it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.57batch/s]\u001B[A\n",
      "135it [01:27,  1.56it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.73batch/s]\u001B[A\n",
      "136it [01:28,  1.60it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.72batch/s]\u001B[A\n",
      "137it [01:28,  1.63it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.85batch/s]\u001B[A\n",
      "138it [01:29,  1.69it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.82batch/s]\u001B[A\n",
      "139it [01:29,  1.72it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.65batch/s]\u001B[A\n",
      "140it [01:30,  1.70it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TooLongTextException: the restrictive measures - Sentence too long for TSC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.56batch/s]\u001B[A\n",
      "142it [01:31,  2.13it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.53batch/s]\u001B[A\n",
      "143it [01:31,  1.94it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.67batch/s]\u001B[A\n",
      "144it [01:32,  1.86it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.68batch/s]\u001B[A\n",
      "145it [01:33,  1.80it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.65batch/s]\u001B[A\n",
      "146it [01:33,  1.75it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.94batch/s]\u001B[A\n",
      "147it [01:34,  1.80it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.89batch/s]\u001B[A\n",
      "148it [01:34,  1.82it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.78batch/s]\u001B[A\n",
      "149it [01:35,  1.81it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.73batch/s]\u001B[A\n",
      "150it [01:35,  1.78it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.69batch/s]\u001B[A\n",
      "151it [01:36,  1.75it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.88batch/s]\u001B[A\n",
      "152it [01:37,  1.78it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.95batch/s]\u001B[A\n",
      "153it [01:37,  1.82it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.69batch/s]\u001B[A\n",
      "154it [01:38,  1.78it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.76batch/s]\u001B[A\n",
      "155it [01:38,  1.77it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.98batch/s]\u001B[A\n",
      "156it [01:39,  1.83it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.81batch/s]\u001B[A\n",
      "157it [01:39,  1.82it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.93batch/s]\u001B[A\n",
      "158it [01:40,  1.85it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.69batch/s]\u001B[A\n",
      "159it [01:40,  1.79it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.64batch/s]\u001B[A\n",
      "160it [01:41,  1.74it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.32batch/s]\u001B[A\n",
      "161it [01:42,  1.58it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.13batch/s]\u001B[A\n",
      "162it [01:43,  1.41it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.46batch/s]\u001B[A\n",
      "163it [01:43,  1.42it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.67batch/s]\u001B[A\n",
      "164it [01:44,  1.49it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.85batch/s]\u001B[A\n",
      "165it [01:45,  1.58it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.63batch/s]\u001B[A\n",
      "166it [01:45,  1.59it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.69batch/s]\u001B[A\n",
      "167it [01:46,  1.61it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.68batch/s]\u001B[A\n",
      "168it [01:46,  1.63it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.71batch/s]\u001B[A\n",
      "169it [01:47,  1.65it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.53batch/s]\u001B[A\n",
      "170it [01:48,  1.61it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.68batch/s]\u001B[A\n",
      "171it [01:48,  1.63it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.76batch/s]\u001B[A\n",
      "172it [01:49,  1.66it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.75batch/s]\u001B[A\n",
      "173it [01:49,  1.69it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.81batch/s]\u001B[A\n",
      "174it [01:50,  1.72it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.76batch/s]\u001B[A\n",
      "175it [01:50,  1.73it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.75batch/s]\u001B[A\n",
      "176it [01:51,  1.73it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.67batch/s]\u001B[A\n",
      "177it [01:52,  1.71it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.69batch/s]\u001B[A\n",
      "178it [01:52,  1.70it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.64batch/s]\u001B[A\n",
      "179it [01:53,  1.68it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.75batch/s]\u001B[A\n",
      "180it [01:53,  1.70it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.62batch/s]\u001B[A\n",
      "181it [01:54,  1.67it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.58batch/s]\u001B[A\n",
      "182it [01:55,  1.64it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.68batch/s]\u001B[A\n",
      "183it [01:55,  1.65it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.79batch/s]\u001B[A\n",
      "184it [01:56,  1.69it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.76batch/s]\u001B[A\n",
      "185it [01:56,  1.71it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.77batch/s]\u001B[A\n",
      "186it [01:57,  1.72it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.68batch/s]\u001B[A\n",
      "187it [01:58,  1.71it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.66batch/s]\u001B[A\n",
      "188it [01:58,  1.69it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.82batch/s]\u001B[A\n",
      "189it [01:59,  1.73it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.76batch/s]\u001B[A\n",
      "190it [01:59,  1.73it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.83batch/s]\u001B[A\n",
      "191it [02:00,  1.76it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.79batch/s]\u001B[A\n",
      "192it [02:00,  1.76it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.90batch/s]\u001B[A\n",
      "193it [02:01,  1.80it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.80batch/s]\u001B[A\n",
      "194it [02:01,  1.80it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.87batch/s]\u001B[A\n",
      "195it [02:02,  1.81it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.85batch/s]\u001B[A\n",
      "196it [02:03,  1.82it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.64batch/s]\u001B[A\n",
      "197it [02:03,  1.76it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.43batch/s]\u001B[A\n",
      "198it [02:04,  1.64it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.90batch/s]\u001B[A\n",
      "199it [02:04,  1.71it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.83batch/s]\u001B[A\n",
      "200it [02:05,  1.74it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.87batch/s]\u001B[A\n",
      "201it [02:06,  1.77it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.89batch/s]\u001B[A\n",
      "202it [02:06,  1.80it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.92batch/s]\u001B[A\n",
      "203it [02:07,  1.83it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.75batch/s]\u001B[A\n",
      "204it [02:07,  1.80it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.85batch/s]\u001B[A\n",
      "205it [02:08,  1.81it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.33batch/s]\u001B[A\n",
      "206it [02:08,  1.63it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.81batch/s]\u001B[A\n",
      "207it [02:09,  1.68it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.49batch/s]\u001B[A\n",
      "208it [02:10,  1.62it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.43batch/s]\u001B[A\n",
      "209it [02:10,  1.55it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.39batch/s]\u001B[A\n",
      "210it [02:11,  1.50it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.44batch/s]\u001B[A\n",
      "211it [02:12,  1.48it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.85batch/s]\u001B[A\n",
      "212it [02:12,  1.57it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.82batch/s]\u001B[A\n",
      "213it [02:13,  1.63it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.83batch/s]\u001B[A\n",
      "214it [02:13,  1.69it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.79batch/s]\u001B[A\n",
      "215it [02:14,  1.71it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.86batch/s]\u001B[A\n",
      "216it [02:15,  1.75it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.40batch/s]\u001B[A\n",
      "217it [02:15,  1.62it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.52batch/s]\u001B[A\n",
      "218it [02:16,  1.59it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.48batch/s]\u001B[A\n",
      "219it [02:17,  1.55it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.80batch/s]\u001B[A\n",
      "220it [02:17,  1.61it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.81batch/s]\u001B[A\n",
      "221it [02:18,  1.66it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.57batch/s]\u001B[A\n",
      "222it [02:18,  1.63it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.39batch/s]\u001B[A\n",
      "223it [02:19,  1.55it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.49batch/s]\u001B[A\n",
      "224it [02:20,  1.53it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.40batch/s]\u001B[A\n",
      "225it [02:20,  1.48it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.47batch/s]\u001B[A\n",
      "226it [02:21,  1.48it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.23batch/s]\u001B[A\n",
      "227it [02:22,  1.39it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.49batch/s]\u001B[A\n",
      "228it [02:23,  1.42it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.33batch/s]\u001B[A\n",
      "229it [02:23,  1.39it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.40batch/s]\u001B[A\n",
      "230it [02:24,  1.39it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.79batch/s]\u001B[A\n",
      "231it [02:25,  1.49it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.64batch/s]\u001B[A\n",
      "232it [02:25,  1.53it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.69batch/s]\u001B[A\n",
      "233it [02:26,  1.57it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.62batch/s]\u001B[A\n",
      "234it [02:27,  1.58it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.56batch/s]\u001B[A\n",
      "235it [02:27,  1.57it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.71batch/s]\u001B[A\n",
      "236it [02:28,  1.61it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.25batch/s]\u001B[A\n",
      "237it [02:29,  1.48it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.82batch/s]\u001B[A\n",
      "238it [02:29,  1.56it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.86batch/s]\u001B[A\n",
      "239it [02:30,  1.64it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.07batch/s]\u001B[A\n",
      "240it [02:31,  1.41it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.10batch/s]\u001B[A\n",
      "241it [02:32,  1.30it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.10batch/s]\u001B[A\n",
      "242it [02:32,  1.23it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.15batch/s]\u001B[A\n",
      "243it [02:33,  1.20it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:01<00:00,  1.01s/batch]\u001B[A\n",
      "244it [02:34,  1.13it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.81batch/s]\u001B[A\n",
      "245it [02:35,  1.27it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.81batch/s]\u001B[A\n",
      "246it [02:35,  1.39it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.67batch/s]\u001B[A\n",
      "247it [02:36,  1.46it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.91batch/s]\u001B[A\n",
      "248it [02:37,  1.57it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.36batch/s]\u001B[A\n",
      "249it [02:37,  1.50it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.25batch/s]\u001B[A\n",
      "250it [02:38,  1.41it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.23batch/s]\u001B[A\n",
      "251it [02:39,  1.35it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.56batch/s]\u001B[A\n",
      "252it [02:40,  1.40it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.54batch/s]\u001B[A\n",
      "253it [02:40,  1.44it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:01<00:00,  1.37s/batch]\u001B[A\n",
      "254it [02:42,  1.11it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.72batch/s]\u001B[A\n",
      "255it [02:42,  1.24it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.61batch/s]\u001B[A\n",
      "256it [02:43,  1.33it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.49batch/s]\u001B[A\n",
      "257it [02:43,  1.37it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.67batch/s]\u001B[A\n",
      "258it [02:44,  1.45it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.35batch/s]\u001B[A\n",
      "259it [02:45,  1.42it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.32batch/s]\u001B[A\n",
      "260it [02:46,  1.38it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.50batch/s]\u001B[A\n",
      "261it [02:46,  1.42it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.58batch/s]\u001B[A\n",
      "262it [02:47,  1.46it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.19batch/s]\u001B[A\n",
      "263it [02:48,  1.36it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:01<00:00,  1.01s/batch]\u001B[A\n",
      "264it [02:49,  1.23it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:01<00:00,  1.02s/batch]\u001B[A\n",
      "265it [02:50,  1.14it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TooLongTextException: west - Sentence too long for TSC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:01<00:00,  1.02s/batch]\u001B[A\n",
      "267it [02:51,  1.40it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:01<00:00,  1.03s/batch]\u001B[A\n",
      "268it [02:52,  1.26it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TooLongTextException: nato - Sentence too long for TSC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TooLongTextException: west - Sentence too long for TSC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.06batch/s]\u001B[A\n",
      "271it [02:53,  1.82it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.08batch/s]\u001B[A\n",
      "272it [02:54,  1.60it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.03batch/s]\u001B[A\n",
      "273it [02:55,  1.42it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TooLongTextException: nato - Sentence too long for TSC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.05batch/s]\u001B[A\n",
      "275it [02:56,  1.62it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.19batch/s]\u001B[A\n",
      "276it [02:57,  1.50it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.22batch/s]\u001B[A\n",
      "277it [02:57,  1.42it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.45batch/s]\u001B[A\n",
      "278it [02:58,  1.43it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.46batch/s]\u001B[A\n",
      "279it [02:59,  1.43it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.50batch/s]\u001B[A\n",
      "280it [02:59,  1.45it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:01<00:00,  1.03s/batch]\u001B[A\n",
      "281it [03:00,  1.27it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.17batch/s]\u001B[A\n",
      "282it [03:01,  1.24it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.22batch/s]\u001B[A\n",
      "283it [03:02,  1.23it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[ABe aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.18batch/s]\u001B[A\n",
      "284it [03:03,  1.21it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.41batch/s]\u001B[A\n",
      "285it [03:04,  1.26it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.34batch/s]\u001B[A\n",
      "286it [03:04,  1.28it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.31batch/s]\u001B[A\n",
      "287it [03:05,  1.29it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.39batch/s]\u001B[A\n",
      "288it [03:06,  1.32it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.50batch/s]\u001B[A\n",
      "289it [03:07,  1.36it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.41batch/s]\u001B[A\n",
      "290it [03:07,  1.37it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.53batch/s]\u001B[A\n",
      "291it [03:08,  1.41it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.56batch/s]\u001B[A\n",
      "292it [03:09,  1.45it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.73batch/s]\u001B[A\n",
      "293it [03:09,  1.53it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.73batch/s]\u001B[A\n",
      "294it [03:10,  1.58it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.70batch/s]\u001B[A\n",
      "295it [03:10,  1.61it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.83batch/s]\u001B[A\n",
      "296it [03:11,  1.67it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.76batch/s]\u001B[A\n",
      "297it [03:11,  1.70it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.61batch/s]\u001B[A\n",
      "298it [03:12,  1.66it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.73batch/s]\u001B[A\n",
      "299it [03:13,  1.67it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.70batch/s]\u001B[A\n",
      "300it [03:13,  1.68it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.73batch/s]\u001B[A\n",
      "301it [03:14,  1.69it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.67batch/s]\u001B[A\n",
      "302it [03:14,  1.68it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.68batch/s]\u001B[A\n",
      "303it [03:15,  1.68it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.71batch/s]\u001B[A\n",
      "304it [03:16,  1.68it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.73batch/s]\u001B[A\n",
      "305it [03:16,  1.70it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.76batch/s]\u001B[A\n",
      "306it [03:17,  1.71it/s]\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?batch/s]\u001B[A\n",
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  1.73batch/s]\u001B[A\n",
      "307it [03:17,  1.55it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    annotation_category                                         annotation  \\\n",
       "0                 blame   has a sordid history of not keeping its promises   \n",
       "1                 blame  might be too weighed down by other issues - th...   \n",
       "2                 blame  constantly providing weapons to Ukraine or imp...   \n",
       "3                 blame  should not stop at eliminating sexual violence...   \n",
       "4                praise  Only through cease-fire and the restoration of...   \n",
       "..                  ...                                                ...   \n",
       "302               blame  US inflation will become higher, ordinary peop...   \n",
       "303               blame  US inflation will become higher, ordinary peop...   \n",
       "304               blame  would undermine US oil companies, and they wil...   \n",
       "305               blame  would undermine US oil companies, and they wil...   \n",
       "306               blame                         are doomed to be unpopular   \n",
       "\n",
       "                                                entity  \\\n",
       "0                                                   US   \n",
       "1                                                   US   \n",
       "2                          The international community   \n",
       "3                          The international community   \n",
       "4                                             Dai Bing   \n",
       "..                                                 ...   \n",
       "302       If the US does prohibit oil exports to China   \n",
       "303       If the US does prohibit oil exports to China   \n",
       "304  Prohibiting the export of oil and petroleum pr...   \n",
       "305  Prohibiting the export of oil and petroleum pr...   \n",
       "306  political calculations by politicians like Rub...   \n",
       "\n",
       "                                              sentence  \\\n",
       "0    After all, the US has a sordid history of not ...   \n",
       "1    Besides, the US might be too weighed down by o...   \n",
       "2    A Chinese envoy on Monday warned against const...   \n",
       "3    A Chinese envoy on Monday warned against const...   \n",
       "4    Only through cease-fire and the restoration of...   \n",
       "..                                                 ...   \n",
       "302  The US only has itself to blame for the curren...   \n",
       "303  The US only has itself to blame for the curren...   \n",
       "304  Prohibiting the export of oil and petroleum pr...   \n",
       "305  Prohibiting the export of oil and petroleum pr...   \n",
       "306  Such political calculations by politicians lik...   \n",
       "\n",
       "                 entity_atomized sentiment tsc_sentiment  \n",
       "0                             US  negative      negative  \n",
       "1                             US  positive      positive  \n",
       "2    The international community  negative      positive  \n",
       "3    The international community  negative      positive  \n",
       "4                       Dai Bing  negative       neutral  \n",
       "..                           ...       ...           ...  \n",
       "302                        China  negative       neutral  \n",
       "303                           US  negative      negative  \n",
       "304                        China  negative       neutral  \n",
       "305                           US  negative       neutral  \n",
       "306              Rubio and Scott  negative      negative  \n",
       "\n",
       "[307 rows x 7 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation_category</th>\n",
       "      <th>annotation</th>\n",
       "      <th>entity</th>\n",
       "      <th>sentence</th>\n",
       "      <th>entity_atomized</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tsc_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blame</td>\n",
       "      <td>has a sordid history of not keeping its promises</td>\n",
       "      <td>US</td>\n",
       "      <td>After all, the US has a sordid history of not ...</td>\n",
       "      <td>US</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blame</td>\n",
       "      <td>might be too weighed down by other issues - th...</td>\n",
       "      <td>US</td>\n",
       "      <td>Besides, the US might be too weighed down by o...</td>\n",
       "      <td>US</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blame</td>\n",
       "      <td>constantly providing weapons to Ukraine or imp...</td>\n",
       "      <td>The international community</td>\n",
       "      <td>A Chinese envoy on Monday warned against const...</td>\n",
       "      <td>The international community</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blame</td>\n",
       "      <td>should not stop at eliminating sexual violence...</td>\n",
       "      <td>The international community</td>\n",
       "      <td>A Chinese envoy on Monday warned against const...</td>\n",
       "      <td>The international community</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>praise</td>\n",
       "      <td>Only through cease-fire and the restoration of...</td>\n",
       "      <td>Dai Bing</td>\n",
       "      <td>Only through cease-fire and the restoration of...</td>\n",
       "      <td>Dai Bing</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>blame</td>\n",
       "      <td>US inflation will become higher, ordinary peop...</td>\n",
       "      <td>If the US does prohibit oil exports to China</td>\n",
       "      <td>The US only has itself to blame for the curren...</td>\n",
       "      <td>China</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>blame</td>\n",
       "      <td>US inflation will become higher, ordinary peop...</td>\n",
       "      <td>If the US does prohibit oil exports to China</td>\n",
       "      <td>The US only has itself to blame for the curren...</td>\n",
       "      <td>US</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>blame</td>\n",
       "      <td>would undermine US oil companies, and they wil...</td>\n",
       "      <td>Prohibiting the export of oil and petroleum pr...</td>\n",
       "      <td>Prohibiting the export of oil and petroleum pr...</td>\n",
       "      <td>China</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>blame</td>\n",
       "      <td>would undermine US oil companies, and they wil...</td>\n",
       "      <td>Prohibiting the export of oil and petroleum pr...</td>\n",
       "      <td>Prohibiting the export of oil and petroleum pr...</td>\n",
       "      <td>US</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>blame</td>\n",
       "      <td>are doomed to be unpopular</td>\n",
       "      <td>political calculations by politicians like Rub...</td>\n",
       "      <td>Such political calculations by politicians lik...</td>\n",
       "      <td>Rubio and Scott</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>307 rows × 7 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T18:00:29.209351Z",
     "start_time": "2025-01-19T18:00:29.196630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "merged_dataframe = pd.concat([all_dataframes_Ania, all_dataframes_Agnieszka], ignore_index=True)\n",
    "merged_dataframe"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    annotation_category                                         annotation  \\\n",
       "0                 blame  new arms deliveries to Kiev are aimed at \"prol...   \n",
       "1                 blame  has been sending more advanced and heavier wea...   \n",
       "2                 blame  clearly knows that a prolonged conflict betwee...   \n",
       "3                 blame  has put its national interests into considerat...   \n",
       "4                 blame  With self-interests in mind, the US will not s...   \n",
       "..                  ...                                                ...   \n",
       "406               blame  US inflation will become higher, ordinary peop...   \n",
       "407               blame  US inflation will become higher, ordinary peop...   \n",
       "408               blame  would undermine US oil companies, and they wil...   \n",
       "409               blame  would undermine US oil companies, and they wil...   \n",
       "410               blame                         are doomed to be unpopular   \n",
       "\n",
       "                                                entity  \\\n",
       "0                                                   US   \n",
       "1                                                   US   \n",
       "2                                                   US   \n",
       "3                                                   US   \n",
       "4                                                   US   \n",
       "..                                                 ...   \n",
       "406       If the US does prohibit oil exports to China   \n",
       "407       If the US does prohibit oil exports to China   \n",
       "408  Prohibiting the export of oil and petroleum pr...   \n",
       "409  Prohibiting the export of oil and petroleum pr...   \n",
       "410  political calculations by politicians like Rub...   \n",
       "\n",
       "                                              sentence  entity_atomized  \\\n",
       "0    Speaking to the Rossiya-1 state television cha...               US   \n",
       "1    From the beginning, the US has been sending mo...               US   \n",
       "2    The US clearly knows that a prolonged conflict...               US   \n",
       "3    The US has put its national interests into con...               US   \n",
       "4    With self-interests in mind, the US will not s...               US   \n",
       "..                                                 ...              ...   \n",
       "406  The US only has itself to blame for the curren...            China   \n",
       "407  The US only has itself to blame for the curren...               US   \n",
       "408  Prohibiting the export of oil and petroleum pr...            China   \n",
       "409  Prohibiting the export of oil and petroleum pr...               US   \n",
       "410  Such political calculations by politicians lik...  Rubio and Scott   \n",
       "\n",
       "    sentiment tsc_sentiment  \n",
       "0    negative       neutral  \n",
       "1    negative       neutral  \n",
       "2    positive       neutral  \n",
       "3    positive      positive  \n",
       "4    negative      positive  \n",
       "..        ...           ...  \n",
       "406  negative       neutral  \n",
       "407  negative      negative  \n",
       "408  negative       neutral  \n",
       "409  negative       neutral  \n",
       "410  negative      negative  \n",
       "\n",
       "[411 rows x 7 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation_category</th>\n",
       "      <th>annotation</th>\n",
       "      <th>entity</th>\n",
       "      <th>sentence</th>\n",
       "      <th>entity_atomized</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tsc_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blame</td>\n",
       "      <td>new arms deliveries to Kiev are aimed at \"prol...</td>\n",
       "      <td>US</td>\n",
       "      <td>Speaking to the Rossiya-1 state television cha...</td>\n",
       "      <td>US</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blame</td>\n",
       "      <td>has been sending more advanced and heavier wea...</td>\n",
       "      <td>US</td>\n",
       "      <td>From the beginning, the US has been sending mo...</td>\n",
       "      <td>US</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blame</td>\n",
       "      <td>clearly knows that a prolonged conflict betwee...</td>\n",
       "      <td>US</td>\n",
       "      <td>The US clearly knows that a prolonged conflict...</td>\n",
       "      <td>US</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blame</td>\n",
       "      <td>has put its national interests into considerat...</td>\n",
       "      <td>US</td>\n",
       "      <td>The US has put its national interests into con...</td>\n",
       "      <td>US</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blame</td>\n",
       "      <td>With self-interests in mind, the US will not s...</td>\n",
       "      <td>US</td>\n",
       "      <td>With self-interests in mind, the US will not s...</td>\n",
       "      <td>US</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>blame</td>\n",
       "      <td>US inflation will become higher, ordinary peop...</td>\n",
       "      <td>If the US does prohibit oil exports to China</td>\n",
       "      <td>The US only has itself to blame for the curren...</td>\n",
       "      <td>China</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>blame</td>\n",
       "      <td>US inflation will become higher, ordinary peop...</td>\n",
       "      <td>If the US does prohibit oil exports to China</td>\n",
       "      <td>The US only has itself to blame for the curren...</td>\n",
       "      <td>US</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>blame</td>\n",
       "      <td>would undermine US oil companies, and they wil...</td>\n",
       "      <td>Prohibiting the export of oil and petroleum pr...</td>\n",
       "      <td>Prohibiting the export of oil and petroleum pr...</td>\n",
       "      <td>China</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>blame</td>\n",
       "      <td>would undermine US oil companies, and they wil...</td>\n",
       "      <td>Prohibiting the export of oil and petroleum pr...</td>\n",
       "      <td>Prohibiting the export of oil and petroleum pr...</td>\n",
       "      <td>US</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>blame</td>\n",
       "      <td>are doomed to be unpopular</td>\n",
       "      <td>political calculations by politicians like Rub...</td>\n",
       "      <td>Such political calculations by politicians lik...</td>\n",
       "      <td>Rubio and Scott</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411 rows × 7 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T18:00:29.304344Z",
     "start_time": "2025-01-19T18:00:29.287899Z"
    }
   },
   "cell_type": "code",
   "source": "merged_dataframe = pd.read_csv('merged_dataframe.csv')",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T18:00:29.529564Z",
     "start_time": "2025-01-19T18:00:29.455702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "merged_sentences = pd.DataFrame(pd.concat(all_sentences_Ania + all_sentences_Agnieszka, ignore_index=True))\n",
    "merged_sentences = merged_sentences.rename(columns={'text': 'sentence'})\n",
    "merged_sentences.to_csv('merged_sentences.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T16:50:09.586212100Z",
     "start_time": "2025-01-11T19:21:01.168678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# One-hot encode the 'annotation_category' column for 'blame' and 'praise'\n",
    "one_hot = pd.get_dummies(merged_dataframe['annotation_category'], columns=['blame', 'praise'])\n",
    "merged_dataframe = pd.concat([merged_dataframe, one_hot[['blame', 'praise']]], axis=1)\n",
    "\n",
    "sentiment_map = {'positive': 1, 'neutral': 0, 'negative': -1}\n",
    "merged_dataframe['sentiment'] = merged_dataframe['sentiment'].map(sentiment_map)\n",
    "merged_dataframe['tsc_sentiment'] = merged_dataframe['tsc_sentiment'].map(sentiment_map)\n",
    "#blame and praise to 1 and 0\n",
    "merged_dataframe['blame'] = merged_dataframe['blame'].astype(int)\n",
    "merged_dataframe['praise'] = merged_dataframe['praise'].astype(int)\n",
    "merged_dataframe"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    annotation_category                                         annotation  \\\n",
       "0                 blame  new arms deliveries to Kiev are aimed at \"prol...   \n",
       "1                 blame  has been sending more advanced and heavier wea...   \n",
       "2                 blame  clearly knows that a prolonged conflict betwee...   \n",
       "3                 blame  has put its national interests into considerat...   \n",
       "4                 blame  With self-interests in mind, the US will not s...   \n",
       "..                  ...                                                ...   \n",
       "406               blame  US inflation will become higher, ordinary peop...   \n",
       "407               blame  US inflation will become higher, ordinary peop...   \n",
       "408               blame  would undermine US oil companies, and they wil...   \n",
       "409               blame  would undermine US oil companies, and they wil...   \n",
       "410               blame                         are doomed to be unpopular   \n",
       "\n",
       "                                                entity  \\\n",
       "0                                                   US   \n",
       "1                                                   US   \n",
       "2                                                   US   \n",
       "3                                                   US   \n",
       "4                                                   US   \n",
       "..                                                 ...   \n",
       "406       If the US does prohibit oil exports to China   \n",
       "407       If the US does prohibit oil exports to China   \n",
       "408  Prohibiting the export of oil and petroleum pr...   \n",
       "409  Prohibiting the export of oil and petroleum pr...   \n",
       "410  political calculations by politicians like Rub...   \n",
       "\n",
       "                                              sentence  entity_atomized  \\\n",
       "0    Speaking to the Rossiya-1 state television cha...               US   \n",
       "1    From the beginning, the US has been sending mo...               US   \n",
       "2    The US clearly knows that a prolonged conflict...               US   \n",
       "3    The US has put its national interests into con...               US   \n",
       "4    With self-interests in mind, the US will not s...               US   \n",
       "..                                                 ...              ...   \n",
       "406  The US only has itself to blame for the curren...               US   \n",
       "407  The US only has itself to blame for the curren...            China   \n",
       "408  Prohibiting the export of oil and petroleum pr...               US   \n",
       "409  Prohibiting the export of oil and petroleum pr...            China   \n",
       "410  Such political calculations by politicians lik...  Rubio and Scott   \n",
       "\n",
       "     sentiment  tsc_sentiment  blame  praise  \n",
       "0           -1              0      1       0  \n",
       "1           -1              0      1       0  \n",
       "2            1              0      1       0  \n",
       "3            1              0      1       0  \n",
       "4           -1              0      1       0  \n",
       "..         ...            ...    ...     ...  \n",
       "406         -1              0      1       0  \n",
       "407         -1             -1      1       0  \n",
       "408         -1              0      1       0  \n",
       "409         -1             -1      1       0  \n",
       "410         -1             -1      1       0  \n",
       "\n",
       "[411 rows x 9 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation_category</th>\n",
       "      <th>annotation</th>\n",
       "      <th>entity</th>\n",
       "      <th>sentence</th>\n",
       "      <th>entity_atomized</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tsc_sentiment</th>\n",
       "      <th>blame</th>\n",
       "      <th>praise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blame</td>\n",
       "      <td>new arms deliveries to Kiev are aimed at \"prol...</td>\n",
       "      <td>US</td>\n",
       "      <td>Speaking to the Rossiya-1 state television cha...</td>\n",
       "      <td>US</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blame</td>\n",
       "      <td>has been sending more advanced and heavier wea...</td>\n",
       "      <td>US</td>\n",
       "      <td>From the beginning, the US has been sending mo...</td>\n",
       "      <td>US</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blame</td>\n",
       "      <td>clearly knows that a prolonged conflict betwee...</td>\n",
       "      <td>US</td>\n",
       "      <td>The US clearly knows that a prolonged conflict...</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blame</td>\n",
       "      <td>has put its national interests into considerat...</td>\n",
       "      <td>US</td>\n",
       "      <td>The US has put its national interests into con...</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blame</td>\n",
       "      <td>With self-interests in mind, the US will not s...</td>\n",
       "      <td>US</td>\n",
       "      <td>With self-interests in mind, the US will not s...</td>\n",
       "      <td>US</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>blame</td>\n",
       "      <td>US inflation will become higher, ordinary peop...</td>\n",
       "      <td>If the US does prohibit oil exports to China</td>\n",
       "      <td>The US only has itself to blame for the curren...</td>\n",
       "      <td>US</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>blame</td>\n",
       "      <td>US inflation will become higher, ordinary peop...</td>\n",
       "      <td>If the US does prohibit oil exports to China</td>\n",
       "      <td>The US only has itself to blame for the curren...</td>\n",
       "      <td>China</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>blame</td>\n",
       "      <td>would undermine US oil companies, and they wil...</td>\n",
       "      <td>Prohibiting the export of oil and petroleum pr...</td>\n",
       "      <td>Prohibiting the export of oil and petroleum pr...</td>\n",
       "      <td>US</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>blame</td>\n",
       "      <td>would undermine US oil companies, and they wil...</td>\n",
       "      <td>Prohibiting the export of oil and petroleum pr...</td>\n",
       "      <td>Prohibiting the export of oil and petroleum pr...</td>\n",
       "      <td>China</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>blame</td>\n",
       "      <td>are doomed to be unpopular</td>\n",
       "      <td>political calculations by politicians like Rub...</td>\n",
       "      <td>Such political calculations by politicians lik...</td>\n",
       "      <td>Rubio and Scott</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411 rows × 9 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T16:50:09.591106800Z",
     "start_time": "2025-01-11T19:21:01.337775Z"
    }
   },
   "cell_type": "code",
   "source": "merged_dataframe.to_csv('merged_dataframe.csv', index=False)",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T16:50:09.603104400Z",
     "start_time": "2025-01-11T19:21:01.409681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_df = merged_dataframe[['sentence', 'blame', 'praise']]\n",
    "final_df = merged_sentences.merge(final_df, left_on='sentence', right_on='sentence', how='left')\n",
    "final_df = final_df.fillna(0)\n",
    "final_df['blame'] = final_df['blame'].astype(int)\n",
    "final_df['praise'] = final_df['praise'].astype(int)\n",
    "final_df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                sentence  blame  praise\n",
       "0      Speaking to the Rossiya-1 state television cha...      1       0\n",
       "1      \"Putin's remarks came a few days after US Pres...      0       0\n",
       "2         \"Putin did not specify which targets he meant.      0       0\n",
       "3      Song Zhongping, a Beijing-based military exper...      0       0\n",
       "4      From the beginning, the US has been sending mo...      1       0\n",
       "...                                                  ...    ...     ...\n",
       "12960  That must be respected, as we would expect Chi...      0       0\n",
       "12961  Of course, one can have opinions on these things.      0       0\n",
       "12962         One can even make criticisms if one wants.      0       0\n",
       "12963  But they shouldn't interfere in state relation...      0       0\n",
       "12964    So it's not really a direct concern of Britain.      0       0\n",
       "\n",
       "[12965 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>blame</th>\n",
       "      <th>praise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Speaking to the Rossiya-1 state television cha...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Putin's remarks came a few days after US Pres...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Putin did not specify which targets he meant.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Song Zhongping, a Beijing-based military exper...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From the beginning, the US has been sending mo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12960</th>\n",
       "      <td>That must be respected, as we would expect Chi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12961</th>\n",
       "      <td>Of course, one can have opinions on these things.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12962</th>\n",
       "      <td>One can even make criticisms if one wants.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12963</th>\n",
       "      <td>But they shouldn't interfere in state relation...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12964</th>\n",
       "      <td>So it's not really a direct concern of Britain.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12965 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T16:50:09.605103800Z",
     "start_time": "2025-01-11T19:21:01.545334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Balance the final_df\n",
    "blame_df = final_df[final_df['blame'] == 1]\n",
    "praise_df = final_df[final_df['praise'] == 1]\n",
    "neutral_df = final_df[(final_df['blame'] == 0) & (final_df['praise'] == 0)]\n",
    "\n",
    "# Calculate the minimum size to balance the classes\n",
    "min_size = min(len(blame_df), len(praise_df))\n",
    "max_size = max(len(blame_df), len(praise_df))\n",
    "\n",
    "\n",
    "neutral_sampled = neutral_df.sample(3*len(blame_df), random_state=42)\n",
    "final_balanced_df = pd.concat([blame_df, praise_df, neutral_sampled], ignore_index=True)\n",
    "final_balanced_df = final_balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "final_balanced_df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                               sentence  blame  praise\n",
       "0     And in case of nuclear war we will become prim...      0       0\n",
       "1     The key question is whether China can prevail ...      0       0\n",
       "2     No one should underestimate the strong resolve...      0       1\n",
       "3     In fact, it is the desire for our output from ...      0       0\n",
       "4     So do you think the national security law in H...      0       0\n",
       "...                                                 ...    ...     ...\n",
       "1297  GT: How do you evaluate the establishment of a...      0       0\n",
       "1298  By Saturday, a total of 108 vehicles and 350.6...      0       0\n",
       "1299  They deal the card \"responsible for food crisi...      0       0\n",
       "1300  However, the Conservative government has not c...      0       0\n",
       "1301  Ports in North China's Inner Mongolia Autonomo...      0       0\n",
       "\n",
       "[1302 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>blame</th>\n",
       "      <th>praise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>And in case of nuclear war we will become prim...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The key question is whether China can prevail ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No one should underestimate the strong resolve...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In fact, it is the desire for our output from ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So do you think the national security law in H...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>GT: How do you evaluate the establishment of a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>By Saturday, a total of 108 vehicles and 350.6...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>They deal the card \"responsible for food crisi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>However, the Conservative government has not c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>Ports in North China's Inner Mongolia Autonomo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1302 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T16:50:09.606179100Z",
     "start_time": "2025-01-11T19:42:17.241037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "merged_dataframe = pd.read_csv('merged_dataframe.csv')\n",
    "merged_dataframe['annotation'] = merged_dataframe['annotation_category'].map({'blame': -1, 'praise': 1})\n",
    "merged_dataframe\n",
    "#map annotation category to 1 and 0"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    annotation_category  annotation  \\\n",
       "0                 blame        -1.0   \n",
       "1                 blame        -1.0   \n",
       "2                 blame        -1.0   \n",
       "3                 blame        -1.0   \n",
       "4                 blame        -1.0   \n",
       "..                  ...         ...   \n",
       "406               blame        -1.0   \n",
       "407               blame        -1.0   \n",
       "408               blame        -1.0   \n",
       "409               blame        -1.0   \n",
       "410               blame        -1.0   \n",
       "\n",
       "                                                entity  \\\n",
       "0                                                   US   \n",
       "1                                                   US   \n",
       "2                                                   US   \n",
       "3                                                   US   \n",
       "4                                                   US   \n",
       "..                                                 ...   \n",
       "406       If the US does prohibit oil exports to China   \n",
       "407       If the US does prohibit oil exports to China   \n",
       "408  Prohibiting the export of oil and petroleum pr...   \n",
       "409  Prohibiting the export of oil and petroleum pr...   \n",
       "410  political calculations by politicians like Rub...   \n",
       "\n",
       "                                              sentence  entity_atomized  \\\n",
       "0    Speaking to the Rossiya-1 state television cha...               US   \n",
       "1    From the beginning, the US has been sending mo...               US   \n",
       "2    The US clearly knows that a prolonged conflict...               US   \n",
       "3    The US has put its national interests into con...               US   \n",
       "4    With self-interests in mind, the US will not s...               US   \n",
       "..                                                 ...              ...   \n",
       "406  The US only has itself to blame for the curren...               US   \n",
       "407  The US only has itself to blame for the curren...            China   \n",
       "408  Prohibiting the export of oil and petroleum pr...               US   \n",
       "409  Prohibiting the export of oil and petroleum pr...            China   \n",
       "410  Such political calculations by politicians lik...  Rubio and Scott   \n",
       "\n",
       "     sentiment  tsc_sentiment  blame  praise  \n",
       "0           -1              0      1       0  \n",
       "1           -1              0      1       0  \n",
       "2            1              0      1       0  \n",
       "3            1              0      1       0  \n",
       "4           -1              0      1       0  \n",
       "..         ...            ...    ...     ...  \n",
       "406         -1              0      1       0  \n",
       "407         -1             -1      1       0  \n",
       "408         -1              0      1       0  \n",
       "409         -1             -1      1       0  \n",
       "410         -1             -1      1       0  \n",
       "\n",
       "[411 rows x 9 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation_category</th>\n",
       "      <th>annotation</th>\n",
       "      <th>entity</th>\n",
       "      <th>sentence</th>\n",
       "      <th>entity_atomized</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tsc_sentiment</th>\n",
       "      <th>blame</th>\n",
       "      <th>praise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blame</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>US</td>\n",
       "      <td>Speaking to the Rossiya-1 state television cha...</td>\n",
       "      <td>US</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blame</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>US</td>\n",
       "      <td>From the beginning, the US has been sending mo...</td>\n",
       "      <td>US</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blame</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>US</td>\n",
       "      <td>The US clearly knows that a prolonged conflict...</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blame</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>US</td>\n",
       "      <td>The US has put its national interests into con...</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blame</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>US</td>\n",
       "      <td>With self-interests in mind, the US will not s...</td>\n",
       "      <td>US</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>blame</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>If the US does prohibit oil exports to China</td>\n",
       "      <td>The US only has itself to blame for the curren...</td>\n",
       "      <td>US</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>blame</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>If the US does prohibit oil exports to China</td>\n",
       "      <td>The US only has itself to blame for the curren...</td>\n",
       "      <td>China</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>blame</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Prohibiting the export of oil and petroleum pr...</td>\n",
       "      <td>Prohibiting the export of oil and petroleum pr...</td>\n",
       "      <td>US</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>blame</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Prohibiting the export of oil and petroleum pr...</td>\n",
       "      <td>Prohibiting the export of oil and petroleum pr...</td>\n",
       "      <td>China</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>blame</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>political calculations by politicians like Rub...</td>\n",
       "      <td>Such political calculations by politicians lik...</td>\n",
       "      <td>Rubio and Scott</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411 rows × 9 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T16:50:09.606179100Z",
     "start_time": "2025-01-11T19:42:53.765119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot correlation matrix using seaborn\n",
    "correlation_data = merged_dataframe[['sentiment', 'tsc_sentiment', 'annotation']]\n",
    "correlation_matrix = correlation_data.corr()\n",
    "# Custom cmap green to lightgray to red\n",
    "cmap = sns.diverging_palette(125, 10, as_cmap=True, s=85, l=50, sep=20, center=\"light\")\n",
    "# Create the seaborn heatmap with the specified color palette\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=cmap, cbar=True, center=0)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.title(\"Correlation Matrix\", pad=20)\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T16:50:09.606179100Z",
     "start_time": "2025-01-11T20:50:20.378169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.metrics import Recall\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T16:50:09.606179100Z",
     "start_time": "2025-01-11T20:53:30.299172Z"
    }
   },
   "cell_type": "code",
   "source": "merged_dataframe",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    annotation_category  annotation  \\\n",
       "0                 blame        -1.0   \n",
       "1                 blame        -1.0   \n",
       "2                 blame        -1.0   \n",
       "3                 blame        -1.0   \n",
       "4                 blame        -1.0   \n",
       "..                  ...         ...   \n",
       "406               blame        -1.0   \n",
       "407               blame        -1.0   \n",
       "408               blame        -1.0   \n",
       "409               blame        -1.0   \n",
       "410               blame        -1.0   \n",
       "\n",
       "                                                entity  \\\n",
       "0                                                   US   \n",
       "1                                                   US   \n",
       "2                                                   US   \n",
       "3                                                   US   \n",
       "4                                                   US   \n",
       "..                                                 ...   \n",
       "406       If the US does prohibit oil exports to China   \n",
       "407       If the US does prohibit oil exports to China   \n",
       "408  Prohibiting the export of oil and petroleum pr...   \n",
       "409  Prohibiting the export of oil and petroleum pr...   \n",
       "410  political calculations by politicians like Rub...   \n",
       "\n",
       "                                              sentence  entity_atomized  \\\n",
       "0    Speaking to the Rossiya-1 state television cha...               US   \n",
       "1    From the beginning, the US has been sending mo...               US   \n",
       "2    The US clearly knows that a prolonged conflict...               US   \n",
       "3    The US has put its national interests into con...               US   \n",
       "4    With self-interests in mind, the US will not s...               US   \n",
       "..                                                 ...              ...   \n",
       "406  The US only has itself to blame for the curren...               US   \n",
       "407  The US only has itself to blame for the curren...            China   \n",
       "408  Prohibiting the export of oil and petroleum pr...               US   \n",
       "409  Prohibiting the export of oil and petroleum pr...            China   \n",
       "410  Such political calculations by politicians lik...  Rubio and Scott   \n",
       "\n",
       "     sentiment  tsc_sentiment  blame  praise  \n",
       "0           -1              0      1       0  \n",
       "1           -1              0      1       0  \n",
       "2            1              0      1       0  \n",
       "3            1              0      1       0  \n",
       "4           -1              0      1       0  \n",
       "..         ...            ...    ...     ...  \n",
       "406         -1              0      1       0  \n",
       "407         -1             -1      1       0  \n",
       "408         -1              0      1       0  \n",
       "409         -1             -1      1       0  \n",
       "410         -1             -1      1       0  \n",
       "\n",
       "[411 rows x 9 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation_category</th>\n",
       "      <th>annotation</th>\n",
       "      <th>entity</th>\n",
       "      <th>sentence</th>\n",
       "      <th>entity_atomized</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tsc_sentiment</th>\n",
       "      <th>blame</th>\n",
       "      <th>praise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blame</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>US</td>\n",
       "      <td>Speaking to the Rossiya-1 state television cha...</td>\n",
       "      <td>US</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blame</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>US</td>\n",
       "      <td>From the beginning, the US has been sending mo...</td>\n",
       "      <td>US</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blame</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>US</td>\n",
       "      <td>The US clearly knows that a prolonged conflict...</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blame</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>US</td>\n",
       "      <td>The US has put its national interests into con...</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blame</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>US</td>\n",
       "      <td>With self-interests in mind, the US will not s...</td>\n",
       "      <td>US</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>blame</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>If the US does prohibit oil exports to China</td>\n",
       "      <td>The US only has itself to blame for the curren...</td>\n",
       "      <td>US</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>blame</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>If the US does prohibit oil exports to China</td>\n",
       "      <td>The US only has itself to blame for the curren...</td>\n",
       "      <td>China</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>blame</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Prohibiting the export of oil and petroleum pr...</td>\n",
       "      <td>Prohibiting the export of oil and petroleum pr...</td>\n",
       "      <td>US</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>blame</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Prohibiting the export of oil and petroleum pr...</td>\n",
       "      <td>Prohibiting the export of oil and petroleum pr...</td>\n",
       "      <td>China</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>blame</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>political calculations by politicians like Rub...</td>\n",
       "      <td>Such political calculations by politicians lik...</td>\n",
       "      <td>Rubio and Scott</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411 rows × 9 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T16:50:09.606179100Z",
     "start_time": "2025-01-11T21:08:10.764979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "final_df = merged_dataframe[['sentence', 'sentiment', 'blame', 'praise']]\n",
    "# Tokenization and padding\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(final_df['sentence'])\n",
    "sequences = tokenizer.texts_to_sequences(final_df['sentence'])\n",
    "padded_sequences = pad_sequences(sequences, maxlen=100, padding='post')\n",
    "print(padded_sequences)\n",
    "\n",
    "# Prepare the labels\n",
    "labels_blame_praise = final_df[['blame', 'praise']].values\n",
    "labels_sentiment = final_df['sentiment'].values\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train_blame_praise, y_test_blame_praise = train_test_split(\n",
    "    padded_sequences, labels_blame_praise, test_size=0.2, random_state=42\n",
    ")\n",
    "y_train_sentiment, y_test_sentiment = train_test_split(\n",
    "    labels_sentiment, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define the multi-task model\n",
    "input_layer = Input(shape=(100,))\n",
    "embedding_layer = Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128, input_length=100)(input_layer)\n",
    "lstm_layer = LSTM(64, return_sequences=False)(embedding_layer)\n",
    "\n",
    "# Output 1: For blame and praise (categorical)\n",
    "output_blame_praise = Dense(2, activation='softmax', name='blame_praise_output')(lstm_layer)\n",
    "\n",
    "# Output 2: For sentiment (regression: -1, 0, 1)\n",
    "output_sentiment = Dense(1, activation='tanh', name='sentiment_output')(lstm_layer)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=[output_blame_praise, output_sentiment])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={'blame_praise_output': 'categorical_crossentropy', 'sentiment_output': 'mse'},\n",
    "    metrics={'blame_praise_output': 'accuracy', 'sentiment_output': 'mae'}\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    {'blame_praise_output': y_train_blame_praise, 'sentiment_output': y_train_sentiment},\n",
    "    epochs=5,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, {'blame_praise_output': y_test_blame_praise, 'sentiment_output': y_test_sentiment}),\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_blame_praise, y_pred_sentiment = model.predict(X_test)\n",
    "\n",
    "# Classification report for blame and praise\n",
    "y_pred_blame_praise_classes = (y_pred_blame_praise > 0.5).astype(int)\n",
    "print(classification_report(y_test_blame_praise, y_pred_blame_praise_classes, target_names=['blame', 'praise']))\n",
    "\n",
    "# Mean Absolute Error for sentiment\n",
    "mae_sentiment = sum(abs(y_pred_sentiment.flatten() - y_test_sentiment)) / len(y_test_sentiment)\n",
    "print(f\"Mean Absolute Error for Sentiment: {mae_sentiment}\")\n",
    "\n",
    "# Generate and visualize the confusion matrix for blame and praise\n",
    "conf_matrix = confusion_matrix(y_test_blame_praise.argmax(axis=1), y_pred_blame_praise_classes.argmax(axis=1))\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Greens\", xticklabels=['blame', 'praise'], yticklabels=['blame', 'praise'])\n",
    "plt.title(\"Confusion Matrix for Blame and Praise\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1129    3    1 ...    0    0    0]\n",
      " [  25    1  270 ...    0    0    0]\n",
      " [   1   11 1459 ...    0    0    0]\n",
      " ...\n",
      " [2017    1  846 ...    0    0    0]\n",
      " [2017    1  846 ...    0    0    0]\n",
      " [  70  248 1136 ...    0    0    0]]\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lukas\\PycharmProjects\\Code\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 55ms/step - blame_praise_output_accuracy: 0.6233 - blame_praise_output_loss: 0.6590 - loss: 1.6099 - sentiment_output_loss: 0.9495 - sentiment_output_mae: 0.9480 - val_blame_praise_output_accuracy: 0.6747 - val_blame_praise_output_loss: 0.6068 - val_loss: 1.4749 - val_sentiment_output_loss: 0.8734 - val_sentiment_output_mae: 0.8828\n",
      "Epoch 2/5\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - blame_praise_output_accuracy: 0.7106 - blame_praise_output_loss: 0.5952 - loss: 1.5221 - sentiment_output_loss: 0.9248 - sentiment_output_mae: 0.9353 - val_blame_praise_output_accuracy: 0.6747 - val_blame_praise_output_loss: 0.6123 - val_loss: 1.4333 - val_sentiment_output_loss: 0.8373 - val_sentiment_output_mae: 0.8605\n",
      "Epoch 3/5\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - blame_praise_output_accuracy: 0.7106 - blame_praise_output_loss: 0.5887 - loss: 1.5097 - sentiment_output_loss: 0.9198 - sentiment_output_mae: 0.9251 - val_blame_praise_output_accuracy: 0.6867 - val_blame_praise_output_loss: 0.6042 - val_loss: 1.4159 - val_sentiment_output_loss: 0.8226 - val_sentiment_output_mae: 0.8544\n",
      "Epoch 4/5\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - blame_praise_output_accuracy: 0.7632 - blame_praise_output_loss: 0.5540 - loss: 1.3895 - sentiment_output_loss: 0.8352 - sentiment_output_mae: 0.8730 - val_blame_praise_output_accuracy: 0.7470 - val_blame_praise_output_loss: 0.5995 - val_loss: 1.3846 - val_sentiment_output_loss: 0.7956 - val_sentiment_output_mae: 0.8311\n",
      "Epoch 5/5\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - blame_praise_output_accuracy: 0.7627 - blame_praise_output_loss: 0.5748 - loss: 1.3719 - sentiment_output_loss: 0.7970 - sentiment_output_mae: 0.8506 - val_blame_praise_output_accuracy: 0.7711 - val_blame_praise_output_loss: 0.5922 - val_loss: 1.2955 - val_sentiment_output_loss: 0.7200 - val_sentiment_output_mae: 0.7695\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 70ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       blame       0.75      1.00      0.85        56\n",
      "      praise       1.00      0.30      0.46        27\n",
      "\n",
      "   micro avg       0.77      0.77      0.77        83\n",
      "   macro avg       0.87      0.65      0.66        83\n",
      "weighted avg       0.83      0.77      0.73        83\n",
      " samples avg       0.77      0.77      0.77        83\n",
      "\n",
      "Mean Absolute Error for Sentiment: 0.7694724930158581\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T16:50:09.606179100Z",
     "start_time": "2025-01-11T20:52:25.734818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# One-hot encode the 'annotation_category' column for 'blame' and 'praise'\n",
    "#me\n",
    "\n",
    "df_to_train = merged_dataframe[['sentence', 'annotation']]\n",
    "sentences = df_to_train['sentence'].values\n",
    "labels = df_to_train['annotation'].values\n",
    "\n",
    "# Tokenize and transform sentences into sequences\n",
    "# tokenizer = Tokenizer(num_words=5000, oov_token=\"<OOV>\")\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "\n",
    "# Padding sequences to ensure uniform length\n",
    "max_length = 100\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the model\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Vocabulary size\n",
    "embedding_dim = 64\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(32),\n",
    "    Dense(4, activation='sigmoid'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[Recall(name='recall')])\n",
    "\n",
    "# Train the model\n",
    "epochs = 4\n",
    "batch_size = 64\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lukas\\PycharmProjects\\Code\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No loss to compute. Provide a `loss` argument in `compile()`.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 39\u001B[0m\n\u001B[0;32m     37\u001B[0m epochs \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m4\u001B[39m\n\u001B[0;32m     38\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m64\u001B[39m\n\u001B[1;32m---> 39\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     41\u001B[0m \u001B[38;5;66;03m# Evaluate the model\u001B[39;00m\n\u001B[0;32m     42\u001B[0m test_loss, test_accuracy \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mevaluate(X_test, y_test)\n",
      "File \u001B[1;32m~\\PycharmProjects\\Code\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m    120\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m    121\u001B[0m     \u001B[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m--> 122\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    123\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    124\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\PycharmProjects\\Code\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py:357\u001B[0m, in \u001B[0;36mTrainer.compute_loss\u001B[1;34m(***failed resolving arguments***)\u001B[0m\n\u001B[0;32m    355\u001B[0m     losses\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_aggregate_additional_loss(loss))\n\u001B[0;32m    356\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m backend\u001B[38;5;241m.\u001B[39mbackend() \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mjax\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(losses) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 357\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    358\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo loss to compute. Provide a `loss` argument in `compile()`.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    359\u001B[0m     )\n\u001B[0;32m    360\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(losses) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    361\u001B[0m     total_loss \u001B[38;5;241m=\u001B[39m losses[\u001B[38;5;241m0\u001B[39m]\n",
      "\u001B[1;31mValueError\u001B[0m: No loss to compute. Provide a `loss` argument in `compile()`."
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T16:50:09.606179100Z",
     "start_time": "2025-01-07T01:52:19.563116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare the entire dataset (merged sentences with blame and praise)\n",
    "X_full = tokenizer.texts_to_sequences(final_df['sentence'])\n",
    "X_full = pad_sequences(X_full, maxlen=max_length)\n",
    "\n",
    "# Get predictions for the whole dataset\n",
    "y_full_pred = (model.predict(X_full) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Evaluate the model on the full dataset\n",
    "metrics = model.evaluate(X_full, final_df['blame'])\n",
    "\n",
    "print(f\"Metrics on the full dataset:\")\n",
    "print(f\"Loss: {metrics[0]:.4f}\")\n",
    "print(f\"Recall: {metrics[1]:.4f}\")\n",
    "\n",
    "# Generate confusion matrix for the full dataset\n",
    "conf_matrix_full = confusion_matrix(final_df['blame'], y_full_pred)\n",
    "print(\"Confusion Matrix for Full Dataset:\")\n",
    "print(conf_matrix_full)\n",
    "\n",
    "# Visualize the full dataset confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix_full, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Not Blame\", \"Blame\"], yticklabels=[\"Not Blame\", \"Blame\"])\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix for Full Dataset\")\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 12s 27ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\lukas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2042, in test_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\lukas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2025, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\lukas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2013, in run_step  **\n        outputs = model.test_step(data)\n    File \"C:\\Users\\lukas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1895, in test_step\n        self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\lukas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1185, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\lukas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\lukas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\lukas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\lukas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py\", line 2532, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"C:\\Users\\lukas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py\", line 5824, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 16) vs (None, 1)).\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[130], line 9\u001B[0m\n\u001B[0;32m      6\u001B[0m y_full_pred \u001B[38;5;241m=\u001B[39m (model\u001B[38;5;241m.\u001B[39mpredict(X_full) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0.5\u001B[39m)\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mint32\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# Evaluate the model on the full dataset\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m metrics \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_full\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfinal_df\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mblame\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMetrics on the full dataset:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLoss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmetrics[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileud_jph3c.py:15\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__test_function\u001B[1;34m(iterator)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     14\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m     retval_ \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(step_function), (ag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mself\u001B[39m), ag__\u001B[38;5;241m.\u001B[39mld(iterator)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[0;32m     17\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: in user code:\n\n    File \"C:\\Users\\lukas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2042, in test_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\lukas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2025, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\lukas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2013, in run_step  **\n        outputs = model.test_step(data)\n    File \"C:\\Users\\lukas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1895, in test_step\n        self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\lukas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1185, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\lukas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\lukas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\lukas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\lukas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py\", line 2532, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"C:\\Users\\lukas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py\", line 5824, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 16) vs (None, 1)).\n"
     ]
    }
   ],
   "execution_count": 130
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T16:50:09.606179100Z",
     "start_time": "2025-01-07T00:29:42.222377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "# One-hot encode the 'annotation_category' column for 'blame' and 'praise'\n",
    "df_to_train = merged_dataframe[['sentence', 'praise']]\n",
    "\n",
    "# Prepare data for modeling\n",
    "sentences = df_to_train['sentence'].values\n",
    "labels = df_to_train['praise'].values\n",
    "\n",
    "# Tokenize and transform sentences into sequences\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "\n",
    "# Padding sequences to ensure uniform length\n",
    "max_length = 100\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the model\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Vocabulary size\n",
    "embedding_dim = 64\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(32),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "11/11 [==============================] - 4s 96ms/step - loss: 0.6694 - accuracy: 0.6726 - val_loss: 0.5934 - val_accuracy: 0.7412\n",
      "Epoch 2/5\n",
      "11/11 [==============================] - 0s 44ms/step - loss: 0.5991 - accuracy: 0.7109 - val_loss: 0.5506 - val_accuracy: 0.7412\n",
      "Epoch 3/5\n",
      "11/11 [==============================] - 0s 41ms/step - loss: 0.5672 - accuracy: 0.7227 - val_loss: 0.5356 - val_accuracy: 0.7765\n",
      "Epoch 4/5\n",
      "11/11 [==============================] - 0s 42ms/step - loss: 0.5416 - accuracy: 0.7699 - val_loss: 0.5030 - val_accuracy: 0.8000\n",
      "Epoch 5/5\n",
      "11/11 [==============================] - 0s 42ms/step - loss: 0.5217 - accuracy: 0.7847 - val_loss: 0.4939 - val_accuracy: 0.8000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4939 - accuracy: 0.8000\n",
      "Test Accuracy: 80.00%\n"
     ]
    }
   ],
   "execution_count": 43
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
